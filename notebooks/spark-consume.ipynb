{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install FlagEmbedding\n",
    "\n",
    "# !pip uninstall backports\n",
    "# !pip install backports\n",
    "# !pip install --force-reinstall -v \"setuptools<70\"\n",
    "\n",
    "# !pip install pymilvus==2.4.4\n",
    "\n",
    "# !pip install openai\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, expr\n",
    "import requests\n",
    "from functools import wraps\n",
    "from pymilvus import connections, utility, db, MilvusClient, FieldSchema, CollectionSchema, Collection, DataType\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEYS\n",
    "\n",
    "hf_token = \"hf_\"\n",
    "open_ai_key = \"sk-\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# cache_dir = '/tmp/huggingface_cache'\n",
    "# os.makedirs(cache_dir, exist_ok=True)\n",
    "# os.chmod(cache_dir, 0o777)\n",
    "# os.environ['TRANSFORMERS_CACHE'] = cache_dir\n",
    "\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "api_url = f\"https://api-inference.huggingface.co/pipeline/feature-extraction/{model_id}\"\n",
    "headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"KafkaRawCSVReader\") \\\n",
    "    .config(\"spark.driver.memory\", \"10g\") \\\n",
    "    .config(\"spark.executor.pyspark.memory\", \"2g\") \\\n",
    "    .config(\"spark.driver.maxResultSize\", \"2g\") \\\n",
    "    .config('spark.jars.packages', 'org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0') \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Read raw data from Kafka\n",
    "kafka_df = spark.readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"kafka:29092\") \\\n",
    "    .option(\"subscribe\", \"csv_stream\") \\\n",
    "    .option(\"startingOffsets\", \"earliest\") \\\n",
    "    .load()\n",
    "\n",
    "\n",
    "# Convert Kafka 'value' column to STRING\n",
    "kafka_string_df = kafka_df.selectExpr(\"CAST(value AS STRING)\")\n",
    "\n",
    "\n",
    "semantic_schema = (\"customer aged {Age} is a {Gender} with marital status {Marital_Status} is a {Occupation} with monthly income of {Monthly_Income} \"\n",
    "                   \"has completed {Educational_Qualifications} with family size of {Family_size} belongs to latitude {latitude} and \"\n",
    "                   \"longitude {longitude} with pincode {Pin_code} has given {Feedback} feedback\")\n",
    "\n",
    "\n",
    "def encode(final_sentence):\n",
    "    response = requests.post(api_url, headers=headers, json={\"inputs\": final_sentence, \"options\":{\"wait_for_model\":True}})\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def process_row(row):\n",
    "    csv = tuple(row.asDict().values())\n",
    "    csv_values_temp = tuple(csv[0].split(','))\n",
    "    \n",
    "    csv_values = tuple(value.strip('\"') for value in csv_values_temp)\n",
    "    \n",
    "    data = {\n",
    "        \"Age\": csv_values[0],\n",
    "        \"Gender\": csv_values[1],\n",
    "        \"Marital_Status\": csv_values[2],\n",
    "        \"Occupation\": csv_values[3],\n",
    "        \"Monthly_Income\": csv_values[4],\n",
    "        \"Educational_Qualifications\": csv_values[5],\n",
    "        \"Family_size\": csv_values[6],\n",
    "        \"latitude\": csv_values[7],\n",
    "        \"longitude\": csv_values[8],\n",
    "        \"Pin_code\": csv_values[9],\n",
    "        \"Feedback\": csv_values[10]\n",
    "    }\n",
    "\n",
    "    \n",
    "    final_sentence = semantic_schema.format(\n",
    "        Age=data[\"Age\"],\n",
    "        Gender=data[\"Gender\"],\n",
    "        Marital_Status=data[\"Marital_Status\"],\n",
    "        Occupation=data[\"Occupation\"],\n",
    "        Monthly_Income=data[\"Monthly_Income\"],\n",
    "        Educational_Qualifications=data[\"Educational_Qualifications\"],\n",
    "        Family_size=data[\"Family_size\"],\n",
    "        latitude=data[\"latitude\"],\n",
    "        longitude=data[\"longitude\"],\n",
    "        Pin_code=data[\"Pin_code\"],\n",
    "        Feedback=data[\"Feedback\"]\n",
    "    )\n",
    "    embedded_sentence = encode(final_sentence)\n",
    "\n",
    "    store_embeddings(embedded_sentence, final_sentence)\n",
    "    \n",
    "query = kafka_string_df.writeStream.foreach(process_row).start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "DB_NAME = \"csv_vec_db\"\n",
    "COLLECTION_NAME = \"csv_vec_coll\"\n",
    "connections.connect(host=\"standalone\", port=19530)\n",
    "\n",
    "databases = db.list_database()\n",
    "\n",
    "if DB_NAME not in databases:\n",
    "    print(\"db created\")\n",
    "    database = db.create_database(DB_NAME)\n",
    "    \n",
    "\n",
    "client = MilvusClient(\n",
    "    uri=\"http://standalone:19530\",\n",
    "    db_name=DB_NAME\n",
    ")\n",
    "\n",
    "collections = client.list_collections()\n",
    "print(\"existing collec\",collections)\n",
    "\n",
    "if COLLECTION_NAME not in collections:\n",
    "    id_field = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, description=\"primary id\")\n",
    "    embedding_field = FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=384, description=\"vector\")\n",
    "    text_field = FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=300, description=\"text\")\n",
    "    \n",
    "    schema = CollectionSchema(fields=[id_field, embedding_field,text_field], auto_id=True, enable_dynamic_field=True, description=\"desc of a collection\")\n",
    "\n",
    "    client.create_collection(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        schema = schema,\n",
    "        dimension=5\n",
    "    )\n",
    "    print(\"collection created\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = MilvusClient.prepare_index_params()\n",
    "\n",
    "index_params.add_index(\n",
    "    field_name=\"embedding\",\n",
    "    metric_type=\"COSINE\",\n",
    "    index_type=\"IVF_FLAT\",\n",
    "    index_name=\"vector_index\",\n",
    "    params={ \"nlist\": 128 }\n",
    ")\n",
    "\n",
    "client.create_index(\n",
    "    collection_name=COLLECTION_NAME,\n",
    "    index_params=index_params\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.load_collection(\n",
    "    collection_name=COLLECTION_NAME,\n",
    " )\n",
    "\n",
    "\n",
    "def store_embeddings(vec, text):\n",
    "    client = MilvusClient(\n",
    "    uri=\"http://standalone:19530\",\n",
    "    db_name=DB_NAME\n",
    "    )\n",
    "\n",
    "    print(client)\n",
    "    data=[{\"embedding\": vec, \"text\": text}]\n",
    "    print(data)\n",
    "    \n",
    "    res = client.insert(\n",
    "        collection_name=COLLECTION_NAME,\n",
    "        data=data\n",
    "    )\n",
    "    print(res)\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similar_docs(query_text):\n",
    "    query_vector = encode(query_text)\n",
    "\n",
    "    client = MilvusClient(\n",
    "    uri=\"http://standalone:19530\",\n",
    "    db_name=DB_NAME\n",
    "    )\n",
    "\n",
    "    results = client.search(\n",
    "        collection_name=COLLECTION_NAME, # Replace with the actual name of your collection\n",
    "        # Replace with your query vector\n",
    "        data=[query_vector],\n",
    "        limit=130, # Max. number of search results to return\n",
    "        output_fields=[\"text\"]\n",
    "        # search_params={\"params\": {\"text\"}} # Search parameters\n",
    "    )\n",
    "\n",
    "    result = results[0]\n",
    "\n",
    "    similar_results = []\n",
    "\n",
    "    for res in result:\n",
    "        similar_results.append(res[\"entity\"][\"text\"])\n",
    "    return similar_results\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key = open_ai_key,\n",
    ")\n",
    "\n",
    "question = \"what is the average age of married men\"\n",
    "\n",
    "similar_results = get_similar_docs(question)\n",
    "\n",
    "context = f\"\"\"\n",
    "given {similar_results}\n",
    "\"\"\"\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": context,\n",
    "        },\n",
    "        # {\n",
    "        #     \"role\": \"system\",\n",
    "        #     \"content\": \"you should respond with reasoning, and dont use context window information\",\n",
    "        # },        \n",
    "        {\n",
    "            \"role\":\"user\",\n",
    "            \"content\":question\n",
    "        }\n",
    "            \n",
    "    ],\n",
    "    # model=\"gpt-3.5-turbo\",\n",
    "    model=\"gpt-4o\",\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
